[{"uri":"https://tunneeeee.github.io/Internship/vi/5-security-monitoring-and-response/1-logging-with-cloudwatch/","title":"Ghi log container vào CloudWatch với Fluent Bit","tags":[],"description":"","content":"Nội dung chính Tổng quan Fluent Bit + CloudWatch Chuẩn bị môi trường Triển khai Fluent Bit lên EKS Cấu hình CloudWatch Output Kiểm tra log trên CloudWatch Troubleshooting Ghi chú \u0026amp; thực hành mở rộng Tổng quan Fluent Bit + CloudWatch Fluent Bit là một trình thu thập và chuyển tiếp log nhẹ, hiệu quả cao. Trên EKS, nó giúp:\nThu thập log từ tất cả container trong cluster Chuyển đổi và enrichment log với metadata Kubernetes Gửi log đến CloudWatch Logs với format JSON chuẩn Hỗ trợ filtering và routing log theo namespace, labels Ưu điểm:\nGọn nhẹ: Chỉ ~15MB memory footprint Hiệu suất cao: Xử lý hàng nghìn events/giây Linh hoạt: Hỗ trợ nhiều đích đến (CloudWatch, Elasticsearch, Kafka, S3\u0026hellip;) Cloud-native: Tích hợp sẵn với Kubernetes Chuẩn bị môi trường Kiểm tra EKS cluster # Kiểm tra cluster status kubectl cluster-info # Kiểm tra nodes kubectl get nodes # Tạo namespace logging kubectl create namespace logging Tạo test application (optional) # Tạo log generator để test kubectl create deployment log-generator --image=busybox --namespace=default kubectl patch deployment log-generator -p \u0026#39;{\u0026#34;spec\u0026#34;:{\u0026#34;template\u0026#34;:{\u0026#34;spec\u0026#34;:{\u0026#34;containers\u0026#34;:[{\u0026#34;name\u0026#34;:\u0026#34;busybox\u0026#34;,\u0026#34;command\u0026#34;:[\u0026#34;sh\u0026#34;,\u0026#34;-c\u0026#34;,\u0026#34;while true; do echo \\\u0026#34;[$(date)] Test log message #$((i++)) - This is a test log for CloudWatch\\\u0026#34;; sleep 10; done\u0026#34;],\u0026#34;image\u0026#34;:\u0026#34;busybox\u0026#34;}]}}}}\u0026#39; Triển khai Fluent Bit lên EKS Bước 1: Tạo IAM role cho Fluent Bit Tạo IAM Policy với quyền ghi CloudWatch Logs:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;logs:PutLogEvents\u0026#34;, \u0026#34;logs:DescribeLogStreams\u0026#34;, \u0026#34;logs:DescribeLogGroups\u0026#34;, \u0026#34;logs:CreateLogStream\u0026#34;, \u0026#34;logs:CreateLogGroup\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Tạo IAM Role và gán policy:\n# Tạo trust policy cho IRSA cat \u0026gt; trust-policy.json \u0026lt;\u0026lt; EOF { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Federated\u0026#34;: \u0026#34;arn:aws:iam::YOUR_ACCOUNT_ID:oidc-provider/oidc.eks.ap-southeast-1.amazonaws.com/id/YOUR_OIDC_ID\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRoleWithWebIdentity\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;oidc.eks.ap-southeast-1.amazonaws.com/id/YOUR_OIDC_ID:sub\u0026#34;: \u0026#34;system:serviceaccount:logging:fluent-bit-sa\u0026#34; } } } ] } EOF # Tạo IAM Role aws iam create-role \\ --role-name FluentBitRole \\ --assume-role-policy-document file://trust-policy.json # Gán policy aws iam attach-role-policy \\ --role-name FluentBitRole \\ --policy-arn arn:aws:iam::YOUR_ACCOUNT_ID:policy/FluentBitCloudWatchPolicy Bước 2: Cài Fluent Bit bằng Helm # Thêm Fluent Bit Helm repository helm repo add fluent https://fluent.github.io/helm-charts helm repo update # Cài đặt Fluent Bit với CloudWatch enabled helm install fluent-bit fluent/fluent-bit \\ --namespace logging \\ --create-namespace \\ --set serviceAccount.create=true \\ --set serviceAccount.name=fluent-bit-sa \\ --set serviceAccount.annotations.\u0026#34;eks\\.amazonaws\\.com/role-arn\u0026#34;=\u0026#34;arn:aws:iam::YOUR_ACCOUNT_ID:role/FluentBitRole\u0026#34; Bước 3: Kiểm tra trạng thái deployment # Kiểm tra pod status kubectl get pods -n logging # Xem logs của Fluent Bit kubectl logs -n logging -l app.kubernetes.io/name=fluent-bit --tail=100 # Kiểm tra service account kubectl describe serviceaccount fluent-bit-sa -n logging Cấu hình CloudWatch Output Tạo ConfigMap cho Fluent Bit apiVersion: v1 kind: ConfigMap metadata: name: fluent-bit-config namespace: logging data: fluent-bit.conf: | [SERVICE] Flush 1 Log_Level info Daemon off Parsers_File parsers.conf HTTP_Server On HTTP_Listen 0.0.0.0 HTTP_Port 2020 [INPUT] Name tail Path /var/log/containers/*.log Parser docker Tag kube.* Refresh_Interval 5 Mem_Buf_Limit 50MB Skip_Long_Lines On [FILTER] Name kubernetes Match kube.* Kube_URL https://kubernetes.default.svc:443 Kube_CA_File /var/run/secrets/kubernetes.io/serviceaccount/ca.crt Kube_Token_File /var/run/secrets/kubernetes.io/serviceaccount/token Kube_Tag_Prefix kube.var.log.containers. Merge_Log On Keep_Log Off K8S-Logging.Parser On K8S-Logging.Exclude On [OUTPUT] Name cloudwatch_logs Match * region ap-southeast-1 log_group_name /aws/containerinsights/your-cluster-name/application log_stream_prefix fluent-bit- auto_create_group On log_retention_days 7 parsers.conf: | [PARSER] Name docker Format json Time_Key time Time_Format %Y-%m-%dT%H:%M:%S.%L Time_Keep On Apply configuration kubectl apply -f fluent-bit-config.yaml # Restart Fluent Bit để load config mới kubectl rollout restart daemonset/fluent-bit -n logging Kiểm tra log trên CloudWatch 1. Truy cập CloudWatch Console Mở CloudWatch Console Chọn Log groups từ menu bên trái Tìm log group: /aws/containerinsights/your-cluster-name/application 2. Kiểm tra log streams # Tạo một số test logs kubectl run test-pod --image=nginx --restart=Never kubectl logs test-pod # Kiểm tra logs của demo2 namespace kubectl logs -n demo2 -l app=nginx --tail=10 kubectl logs -n demo2 -l app=backend --tail=10 3. Xem logs trên CloudWatch Ví dụ log format trên CloudWatch:\n{ \u0026#34;time\u0026#34;: \u0026#34;2025-07-16T05:39:39.654Z\u0026#34;, \u0026#34;stream\u0026#34;: \u0026#34;stdout\u0026#34;, \u0026#34;log\u0026#34;: \u0026#34;[Wed Jul 16 05:39:39 UTC 2025] Test log message #1251 - This is a test log for CloudWatch\u0026#34;, \u0026#34;kubernetes\u0026#34;: { \u0026#34;pod_name\u0026#34;: \u0026#34;nginx-5869d7778c-db2lm\u0026#34;, \u0026#34;namespace_name\u0026#34;: \u0026#34;demo2\u0026#34;, \u0026#34;container_name\u0026#34;: \u0026#34;nginx\u0026#34;, \u0026#34;labels\u0026#34;: { \u0026#34;app\u0026#34;: \u0026#34;nginx\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;v1.0\u0026#34; }, \u0026#34;host\u0026#34;: \u0026#34;ip-192-168-39-33.ap-southeast-1.compute.internal\u0026#34; } } 4. Filtering logs theo namespace Chỉ xem logs của demo2 namespace:\n# Thêm filter trong Fluent Bit config [FILTER] Name grep Match kube.* Regex kubernetes.namespace_name demo2 [OUTPUT] Name cloudwatch_logs Match * region ap-southeast-1 log_group_name /aws/containerinsights/demo2-logs log_stream_prefix demo2- auto_create_group On Troubleshooting Vấn đề thường gặp và cách khắc phục 1. Fluent Bit không start được:\n# Kiểm tra logs lỗi kubectl logs -n logging -l app.kubernetes.io/name=fluent-bit # Kiểm tra permissions kubectl describe pod -n logging -l app.kubernetes.io/name=fluent-bit 2. Không thấy logs trên CloudWatch:\n# Kiểm tra AWS credentials kubectl exec -n logging deployment/fluent-bit -- env | grep AWS # Kiểm tra network connectivity kubectl exec -n logging deployment/fluent-bit -- nslookup logs.ap-southeast-1.amazonaws.com # Xem chi tiết logs của Fluent Bit kubectl logs -n logging -l app.kubernetes.io/name=fluent-bit | grep -i \u0026#34;cloudwatch\\|error\u0026#34; 3. Log format không đúng:\n# Kiểm tra parser configuration kubectl get configmap fluent-bit-config -n logging -o yaml # Test parser locally kubectl exec -n logging deployment/fluent-bit -- fluent-bit --dry-run --config /fluent-bit/etc/fluent-bit.conf 4. Lỗi permissions:\n# Kiểm tra IAM role aws sts get-caller-identity # Kiểm tra service account annotation kubectl describe serviceaccount fluent-bit-sa -n logging | grep Annotations Debug commands hữu ích # Xem realtime logs kubectl logs -n logging -l app.kubernetes.io/name=fluent-bit -f # Kiểm tra metrics kubectl port-forward -n logging svc/fluent-bit 2020:2020 curl localhost:2020/api/v1/metrics # Xem cấu hình hiện tại kubectl exec -n logging deployment/fluent-bit -- cat /fluent-bit/etc/fluent-bit.conf Ghi chú \u0026amp; thực hành mở rộng Tối ưu hóa performance # Tăng buffer size cho high-volume logs [INPUT] Name tail Path /var/log/containers/*.log Mem_Buf_Limit 100MB Buffer_Max_Size 1MB Buffer_Chunk_Size 64KB Log routing theo environment # Route logs theo namespace [OUTPUT] Name cloudwatch_logs Match kube.var.log.containers.*production* log_group_name /aws/containerinsights/production-logs [OUTPUT] Name cloudwatch_logs Match kube.var.log.containers.*staging* log_group_name /aws/containerinsights/staging-logs Structured logging # Parse JSON logs [FILTER] Name parser Match kube.* Parser json Key_Name log Cost optimization # Giảm retention để tiết kiệm chi phí [OUTPUT] Name cloudwatch_logs Match * log_retention_days 3 # Exclude debug logs [FILTER] Name grep Match * Exclude log (DEBUG|TRACE) Monitoring Fluent Bit # Enable metrics endpoint [SERVICE] HTTP_Server On HTTP_Listen 0.0.0.0 HTTP_Port 2020 # Prometheus metrics [OUTPUT] Name prometheus_exporter Match * Host 0.0.0.0 Port 2021 Alternative: OpenTelemetry Collector Đối với hệ thống lớn hơn, có thể xem xét:\n# Cài OpenTelemetry Operator kubectl apply -f https://github.com/open-telemetry/opentelemetry-operator/releases/latest/download/opentelemetry-operator.yaml # Cấu hình OpenTelemetry Collector apiVersion: opentelemetry.io/v1alpha1 kind: OpenTelemetryCollector metadata: name: otel-collector spec: config: | receivers: filelog: include: [\u0026#34;/var/log/containers/*.log\u0026#34;] exporters: awscloudwatchlogs: region: ap-southeast-1 log_group_name: \u0026#34;/aws/containerinsights/otel-logs\u0026#34; service: pipelines: logs: receivers: [filelog] exporters: [awscloudwatchlogs] Lưu ý quan trọng:\nTheo dõi chi phí CloudWatch Logs (tính theo GB ingested) Cân nhắc log retention policy phù hợp Sử dụng log aggregation và sampling cho production workloads Kết hợp với CloudWatch Insights để query và analyze logs 👉 Tiếp theo: 5.2 Security Dashboard → để thiết lập monitoring và alerting cho cluster security.\n"},{"uri":"https://tunneeeee.github.io/Internship/vi/4-policy-enforcement-and-runtime-protection/1-opa-gatekeeper/","title":"Quản lý chính sách với OPA Gatekeeper (Windows)","tags":[],"description":"","content":" Nội dung chính Giới thiệu OPA Gatekeeper Cài đặt Helm trên Windows Triển khai Gatekeeper trên EKS Viết và kiểm tra policy Giới thiệu OPA (Open Policy Agent) là công cụ dùng để thực thi chính sách trên nhiều hệ thống. Gatekeeper là một dự án mở rộng giúp áp dụng OPA cho Kubernetes.\nGatekeeper giúp:\nKiểm soát triển khai dựa trên quy tắc (constraint) Ghi log các hành vi vi phạm Ngăn chặn cấu hình không an toàn (ví dụ: cấm image có tag :latest) Cài đặt Helm trên Windows Truy cập trang https://github.com/helm/helm/releases Tải về file: helm-v3.x.x-windows-amd64.zip Giải nén → Lấy file helm.exe Tạo thư mục ví dụ: C:\\Program Files\\helm\\ → copy helm.exe vào Thêm đường dẫn vào Environment Variables \u0026gt; Path Mở PowerShell/CMD và kiểm tra: helm version ✅ Nếu hiện version là thành công.\nTriển khai Gatekeeper trên EKS Bước 1: Thêm Helm repo Gatekeeper helm repo add gatekeeper https://open-policy-agent.github.io/gatekeeper/charts helm repo update Bước 2: Cài đặt Gatekeeper helm install gatekeeper gatekeeper/gatekeeper \\ --namespace gatekeeper-system \\ --create-namespace Bước 3: Kiểm tra pod kubectl get pods -n gatekeeper-system 📸 Chụp ảnh trạng thái Running.\nViết và kiểm tra policy Bước 1: Tạo file template.yaml apiVersion: templates.gatekeeper.sh/v1beta1 kind: ConstraintTemplate metadata: name: k8srequiredimagetag spec: crd: spec: names: kind: K8sRequiredImageTag targets: - target: admission.k8s.gatekeeper.sh rego: | package k8srequiredimagetag violation[\u0026#34;image tag \u0026#39;latest\u0026#39; is not allowed\u0026#34;] { container := input.review.object.spec.containers[_] endswith(container.image, \u0026#34;:latest\u0026#34;) } kubectl apply -f template.yaml Bước 2: Tạo file constraint.yaml apiVersion: constraints.gatekeeper.sh/v1beta1 kind: K8sRequiredImageTag metadata: name: disallow-latest-tag spec: match: kinds: - apiGroups: [\u0026#34;\u0026#34;] kinds: [\u0026#34;Pod\u0026#34;] kubectl apply -f constraint.yaml Bước 3: Tạo pod test bị vi phạm apiVersion: v1 kind: Pod metadata: name: test-pod spec: containers: - name: nginx image: nginx:latest kubectl apply -f test-pod.yaml ➡️ Kết quả: Pod bị từ chối do vi phạm chính sách.\n✅ Ghi chú:\nGatekeeper rất hiệu quả trong việc kiểm soát việc triển khai. Có thể mở rộng viết policy riêng theo yêu cầu. Tiếp theo: 4.2 Giám sát Runtime với Falco →\n"},{"uri":"https://tunneeeee.github.io/Internship/vi/3-container-security-hardening/1-image-scanning-with-trivy/","title":"Quét lỗ hổng container image bằng Trivy (qua Docker)","tags":[],"description":"","content":"Nội dung chính Giới thiệu Trivy Cài đặt và sử dụng Trivy với Docker trên Windows Quét image Docker và phân tích kết quả Ghi chú và Best Practice Giới thiệu Trivy Trivy là công cụ mã nguồn mở hỗ trợ quét:\nLỗ hổng bảo mật trong container image (CVE) Lỗi cấu hình trong IaC như Kubernetes YAML, Terraform, v.v. Hỗ trợ định dạng đầu ra chuẩn: table, JSON, SARIF\u0026hellip; Cài đặt và sử dụng Trivy với Docker trên Windows ✅ Điều kiện Đã cài đặt Docker Desktop cho Windows (WSL2 hoặc Hyper-V) Đảm bảo Docker đang chạy 🐳 Chạy Trivy trực tiếp từ Docker Câu lệnh mẫu (quét image nginx):\ndocker run --rm -v /var/run/docker.sock:/var/run/docker.sock ` -v $env:USERPROFILE\\.trivy-cache:/root/.cache/ ` aquasec/trivy:latest image nginx 💡 Giải thích:\n\u0026ndash;rm: xóa container sau khi chạy xong -v /var/run/docker.sock:/var/run/docker.sock: cho phép Trivy truy cập image trên máy host -v $env:USERPROFILE.trivy-cache:/root/.cache/: mount thư mục cache để tiết kiệm thời gian quét lần sau aquasec/trivy:latest: sử dụng image chính thức từ Docker Hub image nginx: chỉ định lệnh và tên image cần quét 🖼 Ví dụ thực tế với image có lỗ hổng\ndocker run --rm -v /var/run/docker.sock:/var/run/docker.sock ` -v $env:USERPROFILE\\.trivy-cache:/root/.cache/ ` aquasec/trivy:latest image nginxinc/nginx-unprivileged:1.24.0-alpine-slim Quét image Docker và phân tích kết quả Sau khi chạy lệnh, bạn sẽ nhận được kết quả dạng bảng: Total: 27 (UNKNOWN: 2, LOW: 2, MEDIUM: 20, HIGH: 3)\nLibrary Vulnerability Severity Installed Fixed Title libcrypto3 CVE-2024-6119 HIGH 3.1.4-r6 3.1.7-r0 openssl: DoS trong X.509 name checks nginx CVE-2023-44487 HIGH 1.24.0-r1 1.24.0-r7 HTTP/2 vulnerability dẫn đến tấn công DDoS busybox CVE-2023-42366 MEDIUM 1.36.1-r5 1.36.1-r6 Heap-buffer-overflow trong busybox awk ⚠️ Dù đây là image slim và phổ biến, nhưng vẫn tồn tại nhiều lỗ hổng bảo mật (HIGH, MEDIUM). Điều này cho thấy việc quét định kỳ là rất cần thiết.\nKhi chạy lệnh quét, bạn sẽ nhận được bảng chi tiết các gói bị ảnh hưởng, cấp độ nghiêm trọng (Severity), và phiên bản đã vá. Ví dụ phân tích:\nCVE-2024-6119 (HIGH): ảnh hưởng đến openssl gây từ chối dịch vụ (DoS) CVE-2023-44487 (HIGH): ảnh hưởng HTTP/2, có thể bị DDoS CVE-2023-42366 (MEDIUM): lỗi tràn bộ đệm (heap buffer overflow) ✅ Cách xử lý\nLuôn ưu tiên sửa lỗi CRITICAL và HIGH Nếu có thể, dùng phiên bản mới hơn của image (1.24.0-r7, 1.25.x, \u0026hellip;) Tránh dùng :latest, nên cố định phiên bản để kiểm soát an toàn Ghi chú và Best Practice Xuất file kết quả:\ndocker run --rm ` -v /var/run/docker.sock:/var/run/docker.sock ` -v \u0026#34;$env:USERPROFILE/.trivy-cache:/root/.cache\u0026#34; ` -v \u0026#34;$PWD:/root/report\u0026#34; ` aquasec/trivy:latest image -f json -o /root/report/result.json nginx ➡️ Kết quả JSON sẽ lưu tại D:\\pj_aws\\result.json\nTích hợp CI/CD: Bạn có thể tích hợp lệnh quét trên vào:\nGitHub Actions GitLab CI/CD Jenkins, CircleCI\u0026hellip; ✅ Giúp kiểm tra bảo mật tự động mỗi lần build hoặc deploy.\n🎯 Kết luận: Trivy là công cụ không thể thiếu khi triển khai container production. Bạn nên quét image thường xuyên, sử dụng image chính thức, giữ bản cập nhật, và tích hợp CI/CD để đảm bảo an toàn cho hệ thống.\n"},{"uri":"https://tunneeeee.github.io/Internship/vi/1-intro-to-container-security/","title":"Giới thiệu về Bảo mật Container","tags":[],"description":"","content":"🎯 Mục tiêu của chương này Trong chương đầu tiên này, bạn sẽ được làm quen với các khái niệm quan trọng nhất về bảo mật container, từ tổng quan lý thuyết đến kỹ năng thực hành phân tích mối đe doạ. Đây là phần nền tảng cho toàn bộ workshop.\n📚 Nội dung chính 1.1 Tổng quan về Bảo mật Container\nGiới thiệu container là gì, các lớp bảo mật trong vòng đời container, và tổng quan về các công cụ sẽ sử dụng trong workshop như Falco, OPA, NetworkPolicy, Trivy\u0026hellip;\n1.2 Mô hình Mối đe doạ (Threat Modeling)\nTìm hiểu mô hình STRIDE, xác định các điểm tấn công trong hệ thống container, và thực hành vẽ sơ đồ threat model cho một ứng dụng container mẫu.\n✅ Kết quả sau chương này Hiểu rõ lý do tại sao container cần được bảo mật chặt chẽ Nắm được mô hình bảo mật tổng thể cho container: từ build đến runtime Biết cách xác định mối đe doạ tiềm ẩn qua mô hình STRIDE Sẵn sàng để bước vào thực hành triển khai bảo mật trên môi trường AWS 🚀 Bây giờ hãy bắt đầu với phần 1.1 nhé!\n"},{"uri":"https://tunneeeee.github.io/Internship/vi/2-setup-aws-eks/1-create-eks-cluster/","title":"Tạo Cluster EKS trên AWS","tags":[],"description":"","content":"Nội dung chính:\nBước 1: Cài đặt công cụ trên Windows Bước 2: Tạo file cấu hình cluster Bước 3: Tạo cluster bằng lệnh Bước 4: Kiểm tra kết nối với kubectl Ghi chú và lưu ý Bước 1: Cài đặt công cụ trên Windows AWS CLI Truy cập: https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2-windows.html → Tải file .msi, cài đặt như phần mềm bình thường. Sau đó mở CMD và kiểm tra:\naws –version Nếu hiện version là cài thành công.\n⚙️ Cấu hình tài khoản AWS:\nTạo IAM USER Tạo Access keys/ Secret Access Key Mở powershell aws configure Sau đó nhập các thông tin: AWS Access Key ID AWS Secret Access Key Region: ap-southeast-1 Output format: json Cài đặt kubectl Truy cập link chính thức: 👉 https://kubernetes.io/docs/tasks/tools/install-kubectl-windows/ Hoặc dùng choco nếu đã có Chocolatey:\nchoco install kubernetes-cli Kiểm tra lại bằng:\nkubectl version –client Cài đặt eksctl Truy cập: 👉 https://eksctl.io/introduction/#installation Tải file .exe → Đổi tên thành eksctl.exe và: Copy vào thư mục như C:\\Program Files\\eksctl Thêm thư mục đó vào Environment Variables \u0026gt; PATH Hoặc dùng choco nếu đã có Chocolatey:\nchoco install eksctl Kiểm tra lại bằng: eksctl version Bước 2: Tạo file cấu hình cluster Mở Notepad hoặc VS Code, tạo file eks-cluster.yaml với nội dung:\napiVersion: eksctl.io/v1alpha5 kind: ClusterConfig metadata: name: secure-eks region: ap-southeast-1 nodeGroups: - name: ng-1 instanceType: t3.medium desiredCapacity: 2 ssh: allow: true Lưu lại cùng thư mục nơi bạn mở terminal sau này.\nBước 3: Tạo cluster bằng lệnh Mở PowerShell hoặc terminal trong VS Code, chuyển đến thư mục chứa file eks-cluster.yaml, sau đó chạy:\neksctl create cluster -f eks-cluster.yaml Lỗi bạn có thể gặp là: Error: cannot find EC2 key pair \u0026ldquo;~/.ssh/id_rsa.pub\u0026rdquo; 💡 Nguyên nhân: Trong file cấu hình eks-cluster.yaml, bạn có bật SSH cho node group:\nssh: allow: true Khi allow: true, eksctl sẽ cố tìm file ~/.ssh/id_rsa.pub để dùng làm key pair SSH – nhưng hiện tại bạn chưa tạo key này trên máy Windows.\nLúc đó bạn cần tạo key pair SSH thủ công Mở PowerShell và chạy:\nssh-keygen Nhấn Enter liên tục để chấp nhận đường dẫn mặc định (C:\\Users\u0026lt;tên_user\u0026gt;.ssh\\id_rsa)\nSau đó kiểm tra file:\ntype $env:USERPROFILE\\.ssh\\id_rsa.pub Chạy lại lệnh tạo cluster:\neksctl create cluster -f eks-cluster.yaml 📌 eksctl sẽ tự lấy file id_rsa.pub và tạo key pair tương ứng trong AWS EC2.\n⏳ Quá trình tạo có thể mất 10–15 phút. eksctl sẽ tạo: VPC, IAM role, Security Group, Control Plane, EC2 Node…\nBước 4: Kiểm tra kết nối với kubectl Sau khi cluster tạo xong, xác minh kết nối:\nkubectl get nodes ✅ Bạn sẽ thấy 2 node worker đang chạy – EKS đã hoạt động sẵn sàng!\n📸 Chụp ảnh terminal kết quả để sử dụng trong báo cáo workshop.\nGhi chú eksctl sẽ tự tạo VPC và node group nếu chưa có Nên dùng region ap-southeast-1 (Singapore) nếu bạn ở Việt Nam để giảm độ trễ "},{"uri":"https://tunneeeee.github.io/Internship/vi/1-intro-to-container-security/1-overview/","title":"Tổng quan về Bảo mật Container","tags":[],"description":"","content":"Nội dung chính:\nContainer là gì và vì sao cần bảo mật? Các lớp bảo mật container Mục tiêu cuối cùng của workshop Container là gì và vì sao cần bảo mật? Container là một phương pháp đóng gói ứng dụng kèm theo các thư viện và cấu hình để chạy được ở bất kỳ đâu. Tuy nhiên, do tính chất nhẹ và chia sẻ kernel nên container tiềm ẩn nhiều rủi ro bảo mật:\nContainer có thể truy cập file hệ thống host nếu không được giới hạn đúng cách Tấn công “container escape” có thể ảnh hưởng toàn bộ node Lỗi cấu hình (exposed port, privilege mode) dễ bị khai thác Các image từ nguồn không xác thực có thể chứa mã độc Các lớp bảo mật container Bảo mật container không chỉ ở runtime mà cần bảo vệ toàn bộ vòng đời ứng dụng:\nGiai đoạn Biện pháp Build Quét image (Trivy), loại bỏ lỗ hổng Deploy Kiểm soát chính sách (OPA, limit) Runtime Phát hiện bất thường (Falco) Network Giới hạn truy cập (NetworkPolicy) Monitoring Cảnh báo \u0026amp; phản hồi sự cố Mục tiêu cuối cùng của workshop Cuối workshop, bạn sẽ:\nCài đặt cluster EKS với ứng dụng container hoá Thực hiện quét lỗ hổng, kiểm tra benchmark (CIS) Áp dụng NetworkPolicy, OPA, Falco để bảo vệ container Triển khai hệ thống alerting và tự động hóa khắc phục Hiểu và áp dụng mô hình mối đe doạ (STRIDE, ATT\u0026amp;CK) 🧠 Bạn sẽ chụp ảnh lại từng bước và đưa vào nội dung workshop để hướng dẫn người khác triển khai môi trường bảo mật container toàn diện.\n"},{"uri":"https://tunneeeee.github.io/Internship/vi/4-policy-enforcement-and-runtime-protection/2-falco-setup-and-rule/","title":"Giám sát runtime với Falco (Windows)","tags":[],"description":"","content":" Nội dung chính Giới thiệu Falco Cài đặt Falco bằng Helm Kiểm tra cảnh báo runtime Giới thiệu Falco Falco là công cụ giám sát hành vi thời gian thực trong Kubernetes. Nó giúp phát hiện:\nTruy cập bất thường đến hệ thống (vd: /etc/passwd) Sử dụng shell trong container (bash, sh) Ghi đè file nhạy cảm Falco sử dụng kernel syscall để ghi nhận hành vi và phát cảnh báo dựa trên rule.\nCài đặt Falco bằng Helm 🔧 Yêu cầu: Đã cài kubectl, eksctl, AWS CLI, và có cluster EKS hoạt động Bước 1: Cài đặt Helm Truy cập trang https://github.com/helm/helm/releases/latest Tải về file: windows-amd64.zip Giải nén → Lấy file helm.exe Tạo thư mục ví dụ: C:\\Program Files\\helm\\ → copy helm.exe vào Thêm đường dẫn vào Environment Variables \u0026gt; Path Mở PowerShell/CMD và kiểm tra: Xác minh: helm version Bước 2: Thêm repo và cài Falco: helm repo add falcosecurity https://falcosecurity.github.io/charts helm repo update kubectl create ns falco helm install falco falcosecurity/falco -n falco 📸 Chụp ảnh pod Falco đang chạy ở namespace falco để minh họa tài liệu.\nKiểm tra cảnh báo runtime Bước 1: Mở shell bất thường để tạo alert kubectl run -i --tty attacker --image=alpine -- sh Sau đó chạy trong terminal:\ntouch /etc/passwd Bước 2: Xem log Falco kubectl logs -l app=falco -n falco ✅ Kết quả mong đợi:\nFalco Alert: Write below etc detected (user=root command=touch /etc/passwd) 📸 Chụp log Falco có chứa dòng cảnh báo để đưa vào báo cáo.\nGhi chú Falco không ngăn chặn hành vi, chỉ cảnh báo. Muốn tự động phản ứng (4.3), bạn cần kết hợp với Falcosidekick hoặc các công cụ khác. 👉 Tiếp theo: 4.3 Tự động phản ứng với vi phạm bằng Falcosidekick →\n"},{"uri":"https://tunneeeee.github.io/Internship/vi/5-security-monitoring-and-response/2-security-dashboard/","title":"Security Dashboard - Giám sát bảo mật EKS","tags":[],"description":"","content":"Nội dung chính Tổng quan Security Dashboard Thiết lập Amazon GuardDuty Cấu hình AWS Config Rules Tích hợp CloudWatch Security Dashboard Cảnh báo và Automation Tổng quan Security Dashboard Security Dashboard tổng hợp thông tin bảo mật từ nhiều nguồn khác nhau để cung cấp cái nhìn tổng quan về tình trạng bảo mật của EKS cluster.\nKiến trúc tổng quan: EKS Cluster ──→ GuardDuty ──→ Security Hub ──→ CloudWatch Dashboard\r│ │ │ │\r├─→ Config ─────┤ │ │\r└─→ Falco ──────┴──────────────┘ │\r│\rSNS Alerts ←───────────────────────────────────────┘ Thiết lập Amazon GuardDuty Kích hoạt GuardDuty cho EKS # Kích hoạt GuardDuty aws guardduty create-detector --enable # Lấy detector ID DETECTOR_ID=$(aws guardduty list-detectors --query \u0026#39;DetectorIds[0]\u0026#39; --output text) # Kích hoạt EKS Protection aws guardduty update-detector \\ --detector-id $DETECTOR_ID \\ --kubernetes-audit-logs-configuration Enable=true Cấu hình xử lý GuardDuty findings # guardduty-processor.yaml apiVersion: v1 kind: ConfigMap metadata: name: guardduty-processor namespace: security-monitoring data: process-findings.py: | import json import boto3 def lambda_handler(event, context): detail = event[\u0026#39;detail\u0026#39;] finding_type = detail[\u0026#39;type\u0026#39;] severity = detail[\u0026#39;severity\u0026#39;] # Xử lý findings liên quan đến EKS if \u0026#39;Kubernetes\u0026#39; in finding_type: send_to_cloudwatch(detail) # Gửi alert cho findings nghiêm trọng if severity \u0026gt;= 7.0: send_critical_alert(detail) return {\u0026#39;statusCode\u0026#39;: 200} def send_to_cloudwatch(finding): cloudwatch = boto3.client(\u0026#39;cloudwatch\u0026#39;) cloudwatch.put_metric_data( Namespace=\u0026#39;EKS/Security\u0026#39;, MetricData=[{ \u0026#39;MetricName\u0026#39;: \u0026#39;SecurityFinding\u0026#39;, \u0026#39;Value\u0026#39;: finding[\u0026#39;severity\u0026#39;], \u0026#39;Unit\u0026#39;: \u0026#39;Count\u0026#39;, \u0026#39;Dimensions\u0026#39;: [ {\u0026#39;Name\u0026#39;: \u0026#39;FindingType\u0026#39;, \u0026#39;Value\u0026#39;: finding[\u0026#39;type\u0026#39;]} ] }] ) def send_critical_alert(finding): sns = boto3.client(\u0026#39;sns\u0026#39;) sns.publish( TopicArn=\u0026#39;arn:aws:sns:ap-southeast-1:ACCOUNT:eks-security-alerts\u0026#39;, Message=f\u0026#34;Critical EKS Security Alert: {finding[\u0026#39;type\u0026#39;]}\u0026#34;, Subject=\u0026#39;Critical EKS Security Alert\u0026#39; ) Cấu hình AWS Config Rules Triển khai EKS Config Rules # Kích hoạt Config aws configservice put-configuration-recorder \\ --configuration-recorder name=eks-config-recorder,roleARN=arn:aws:iam::ACCOUNT:role/aws-service-role/config.amazonaws.com/AWSServiceRoleForConfig # Tạo EKS-specific rules aws configservice put-config-rule \\ --config-rule \u0026#39;{ \u0026#34;ConfigRuleName\u0026#34;: \u0026#34;eks-cluster-logging-enabled\u0026#34;, \u0026#34;Source\u0026#34;: { \u0026#34;Owner\u0026#34;: \u0026#34;AWS\u0026#34;, \u0026#34;SourceIdentifier\u0026#34;: \u0026#34;EKS_CLUSTER_LOGGING_ENABLED\u0026#34; }, \u0026#34;InputParameters\u0026#34;: \u0026#34;{\\\u0026#34;desiredLogTypes\\\u0026#34;:\\\u0026#34;api,audit,authenticator\\\u0026#34;}\u0026#34; }\u0026#39; aws configservice put-config-rule \\ --config-rule \u0026#39;{ \u0026#34;ConfigRuleName\u0026#34;: \u0026#34;eks-secrets-encrypted\u0026#34;, \u0026#34;Source\u0026#34;: { \u0026#34;Owner\u0026#34;: \u0026#34;AWS\u0026#34;, \u0026#34;SourceIdentifier\u0026#34;: \u0026#34;EKS_SECRETS_ENCRYPTED\u0026#34; } }\u0026#39; Custom Config Rule cho Pod Security # pod-security-rule.py import json import boto3 from kubernetes import client, config def lambda_handler(event, context): # Load kubeconfig config.load_incluster_config() v1 = client.CoreV1Api() # Check pod security standards non_compliant_pods = [] pods = v1.list_pod_for_all_namespaces() for pod in pods.items: if pod.metadata.namespace in [\u0026#39;kube-system\u0026#39;, \u0026#39;kube-public\u0026#39;]: continue violations = check_pod_security(pod) if violations: non_compliant_pods.append({ \u0026#39;name\u0026#39;: pod.metadata.name, \u0026#39;namespace\u0026#39;: pod.metadata.namespace, \u0026#39;violations\u0026#39;: violations }) # Return compliance result return { \u0026#39;complianceType\u0026#39;: \u0026#39;NON_COMPLIANT\u0026#39; if non_compliant_pods else \u0026#39;COMPLIANT\u0026#39;, \u0026#39;annotation\u0026#39;: f\u0026#34;Found {len(non_compliant_pods)} non-compliant pods\u0026#34; } def check_pod_security(pod): violations = [] # Check if pod runs as root if pod.spec.security_context and pod.spec.security_context.run_as_user == 0: violations.append(\u0026#34;Runs as root user\u0026#34;) # Check privileged containers for container in pod.spec.containers: if container.security_context and container.security_context.privileged: violations.append(f\u0026#34;Container {container.name} is privileged\u0026#34;) return violations Tích hợp CloudWatch Security Dashboard Tạo Security Dashboard { \u0026#34;widgets\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;metric\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;metrics\u0026#34;: [ [\u0026#34;EKS/Security\u0026#34;, \u0026#34;SecurityFinding\u0026#34;, \u0026#34;FindingType\u0026#34;, \u0026#34;Kubernetes.Cluster\u0026#34;], [\u0026#34;EKS/Security/Falco\u0026#34;, \u0026#34;SecurityAlert\u0026#34;, \u0026#34;Priority\u0026#34;, \u0026#34;CRITICAL\u0026#34;], [\u0026#34;AWS/Config\u0026#34;, \u0026#34;ComplianceByConfigRule\u0026#34;, \u0026#34;ConfigRuleName\u0026#34;, \u0026#34;eks-cluster-logging-enabled\u0026#34;] ], \u0026#34;period\u0026#34;: 300, \u0026#34;stat\u0026#34;: \u0026#34;Sum\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;ap-southeast-1\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;Security Overview\u0026#34;, \u0026#34;view\u0026#34;: \u0026#34;timeSeries\u0026#34; } }, { \u0026#34;type\u0026#34;: \u0026#34;log\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;query\u0026#34;: \u0026#34;SOURCE \u0026#39;/aws/eks/security/falco\u0026#39;\\n| fields @timestamp, rule, priority, output\\n| filter priority = \\\u0026#34;CRITICAL\\\u0026#34;\\n| sort @timestamp desc\\n| limit 10\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;ap-southeast-1\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;Recent Critical Alerts\u0026#34;, \u0026#34;view\u0026#34;: \u0026#34;table\u0026#34; } }, { \u0026#34;type\u0026#34;: \u0026#34;metric\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;metrics\u0026#34;: [ [\u0026#34;EKS/Security/Pods\u0026#34;, \u0026#34;PrivilegedPods\u0026#34;, \u0026#34;Namespace\u0026#34;, \u0026#34;demo2\u0026#34;], [\u0026#34;.\u0026#34;, \u0026#34;RootContainers\u0026#34;, \u0026#34;.\u0026#34;, \u0026#34;.\u0026#34;] ], \u0026#34;period\u0026#34;: 300, \u0026#34;stat\u0026#34;: \u0026#34;Average\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;ap-southeast-1\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;Pod Security Metrics\u0026#34; } } ] } Triển khai Dashboard # Tạo dashboard aws cloudwatch put-dashboard \\ --dashboard-name \u0026#34;EKS-Security-Dashboard\u0026#34; \\ --dashboard-body file://eks-security-dashboard.json # Tạo custom metrics cho pod security kubectl apply -f - \u0026lt;\u0026lt;EOF apiVersion: v1 kind: ServiceAccount metadata: name: security-metrics-collector namespace: security-monitoring --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: name: security-metrics-collector rules: - apiGroups: [\u0026#34;\u0026#34;] resources: [\u0026#34;pods\u0026#34;, \u0026#34;namespaces\u0026#34;] verbs: [\u0026#34;get\u0026#34;, \u0026#34;list\u0026#34;, \u0026#34;watch\u0026#34;] --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: security-metrics-collector roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: security-metrics-collector subjects: - kind: ServiceAccount name: security-metrics-collector namespace: security-monitoring EOF Cảnh báo và Automation Tạo CloudWatch Alarms # Alarm cho Critical Security Findings aws cloudwatch put-metric-alarm \\ --alarm-name \u0026#34;EKS-Critical-Security-Findings\u0026#34; \\ --alarm-description \u0026#34;Critical security findings detected\u0026#34; \\ --metric-name SecurityFinding \\ --namespace EKS/Security \\ --statistic Sum \\ --period 300 \\ --threshold 1 \\ --comparison-operator GreaterThanOrEqualToThreshold \\ --evaluation-periods 1 \\ --alarm-actions arn:aws:sns:ap-southeast-1:ACCOUNT:eks-security-alerts # Alarm cho Falco Critical Alerts aws cloudwatch put-metric-alarm \\ --alarm-name \u0026#34;EKS-Falco-Critical-Alerts\u0026#34; \\ --alarm-description \u0026#34;Falco critical alerts detected\u0026#34; \\ --metric-name SecurityAlert \\ --namespace EKS/Security/Falco \\ --statistic Sum \\ --period 300 \\ --threshold 1 \\ --comparison-operator GreaterThanOrEqualToThreshold \\ --evaluation-periods 1 \\ --alarm-actions arn:aws:sns:ap-southeast-1:ACCOUNT:eks-security-alerts # Alarm cho Pod Security Violations aws cloudwatch put-metric-alarm \\ --alarm-name \u0026#34;EKS-Pod-Security-Violations\u0026#34; \\ --alarm-description \u0026#34;Pod security violations detected\u0026#34; \\ --metric-name PrivilegedPods \\ --namespace EKS/Security/Pods \\ --statistic Average \\ --period 600 \\ --threshold 0 \\ --comparison-operator GreaterThanThreshold \\ --evaluation-periods 2 \\ --alarm-actions arn:aws:sns:ap-southeast-1:ACCOUNT:eks-security-alerts Automated Response # security-response-automation.py import json import boto3 from kubernetes import client, config def lambda_handler(event, context): \u0026#34;\u0026#34;\u0026#34;Automated response to security alerts\u0026#34;\u0026#34;\u0026#34; # Parse CloudWatch alarm message = json.loads(event[\u0026#39;Records\u0026#39;][0][\u0026#39;Sns\u0026#39;][\u0026#39;Message\u0026#39;]) alarm_name = message[\u0026#39;AlarmName\u0026#39;] # Load kubeconfig config.load_incluster_config() v1 = client.CoreV1Api() # Automated responses based on alarm type if \u0026#34;Pod-Security-Violations\u0026#34; in alarm_name: quarantine_violating_pods(v1) elif \u0026#34;Critical-Security-Findings\u0026#34; in alarm_name: isolate_suspicious_workloads(v1) elif \u0026#34;Falco-Critical-Alerts\u0026#34; in alarm_name: scale_down_suspicious_deployments(v1) return {\u0026#39;statusCode\u0026#39;: 200} def quarantine_violating_pods(v1): \u0026#34;\u0026#34;\u0026#34;Quarantine pods with security violations\u0026#34;\u0026#34;\u0026#34; pods = v1.list_pod_for_all_namespaces() for pod in pods.items: if has_security_violation(pod): # Add quarantine label v1.patch_namespaced_pod( name=pod.metadata.name, namespace=pod.metadata.namespace, body={ \u0026#39;metadata\u0026#39;: { \u0026#39;labels\u0026#39;: { \u0026#39;security.policy/quarantine\u0026#39;: \u0026#39;true\u0026#39; } } } ) def isolate_suspicious_workloads(v1): \u0026#34;\u0026#34;\u0026#34;Isolate workloads with security findings\u0026#34;\u0026#34;\u0026#34; # Implementation for workload isolation pass def scale_down_suspicious_deployments(v1): \u0026#34;\u0026#34;\u0026#34;Scale down deployments with critical alerts\u0026#34;\u0026#34;\u0026#34; # Implementation for scaling down pass Tạo SNS Topic và Subscription # Tạo SNS topic aws sns create-topic --name eks-security-alerts # Subscribe email aws sns subscribe \\ --topic-arn arn:aws:sns:ap-southeast-1:ACCOUNT:eks-security-alerts \\ --protocol email \\ --notification-endpoint security@company.com # Subscribe Lambda function aws sns subscribe \\ --topic-arn arn:aws:sns:ap-southeast-1:ACCOUNT:eks-security-alerts \\ --protocol lambda \\ --notification-endpoint arn:aws:lambda:ap-southeast-1:ACCOUNT:function:security-response-automation Tổng kết Security Dashboard cung cấp:\nTổng quan bảo mật tập trung: Tích hợp thông tin từ GuardDuty, Config, và Falco Cảnh báo thời gian thực: Phát hiện và phản ứng nhanh với các mối đe dọa Automation: Tự động hóa phản ứng với các sự cố bảo mật Compliance monitoring: Theo dõi tuân thủ các policy bảo mật Truy vết và phân tích: Lưu trữ và phân tích các sự kiện bảo mật Dashboard này giúp team security có cái nhìn toàn diện về tình trạng bảo mật của EKS cluster và phản ứng kịp thời với các mối đe dọa.\n"},{"uri":"https://tunneeeee.github.io/Internship/vi/3-container-security-hardening/2-cis-benchmark-with-kubebench/","title":"Kiểm tra tuân thủ CIS Benchmark với kube-bench","tags":[],"description":"","content":" Nội dung chính Giới thiệu về CIS Benchmark và kube-bench Triển khai kube-bench trên EKS Phân tích kết quả kiểm tra và khuyến nghị Giới thiệu CIS Kubernetes Benchmark là bộ quy tắc bảo mật chuẩn hóa do Center for Internet Security ban hành. Nó bao gồm các mục kiểm tra từ API Server, Scheduler, Etcd, Kubelet\u0026hellip;\nkube-bench là công cụ của Aqua Security để tự động hóa việc kiểm tra các điểm đó trên cluster Kubernetes.\nTriển khai kube-bench trên EKS Bước 1: Tạo file job yaml Tạo file kube-bench-job.yaml như sau:\napiVersion: batch/v1 kind: Job metadata: name: kube-bench spec: template: spec: containers: - name: kube-bench image: aquasec/kube-bench:latest command: [\u0026#34;kube-bench\u0026#34;, \u0026#34;--benchmark\u0026#34;, \u0026#34;eks\u0026#34;] volumeMounts: - name: var-lib-kubelet mountPath: /var/lib/kubelet readOnly: true - name: etc-systemd mountPath: /etc/systemd readOnly: true - name: var-lib-etcd mountPath: /var/lib/etcd readOnly: true restartPolicy: Never volumes: - name: var-lib-kubelet hostPath: path: /var/lib/kubelet - name: etc-systemd hostPath: path: /etc/systemd - name: var-lib-etcd hostPath: path: /var/lib/etcd backoffLimit: 0 Bước 2: Áp dụng Job lên cluster kubectl apply -f kube-bench-job.yaml ⏳ Chờ vài phút để Job chạy xong.\nBước 3: Xem kết quả kiểm tra kubectl logs job/kube-bench Phân tích kết quả Output sẽ hiển thị các mục kiểm tra theo chuẩn CIS, ví dụ:\n== Summary total ==\r4 checks PASS\r4 checks FAIL\r43 checks WARN ❌ [FAIL]\n\u0026ndash;anonymous-auth=false: tắt quyền truy cập ẩn danh \u0026ndash;authorization-mode=Webhook: cấu hình authorization an toàn \u0026ndash;make-iptables-util-chains=true: xử lý các chuỗi iptables đúng cách 🔧 Cách khắc phục: Sửa file kubelet.service trên từng node theo hướng dẫn systemctl daemon-reload + restart kubelet.\n⚠️ [WARN]\nSử dụng quá nhiều wildcard trong RBAC (roles, clusterroles) Không có NetworkPolicy cho các namespace PSP chưa cấu hình kỹ → cho phép container đặc quyền (privileged) Chưa cấu hình chuẩn IAM / ECR / Secrets trên AWS ✅ [PASS]\nMột số tệp cấu hình kubelet đặt quyền sở hữu và permission đúng (644, root:root) Ghi chú bổ sung kube-bench có thể chạy ở mode host, daemonset, hoặc job, tùy mục đích. Chạy riêng node có label bằng cách dùng nodeSelector Có thể export kết quả sang JSON: kubectl logs job/kube-bench -o json \u0026gt; cis-result.json ✅ Best Practice tổng quát:\nLuôn kiểm tra định kỳ theo CIS Benchmark Không dùng config mặc định của Kubernetes / Kubelet Cố gắng giảm mức độ cảnh báo WARN → FAIL → PASS theo thứ tự ưu tiên Tự động hóa kiểm tra bằng cách tích hợp kube-bench vào CI/CD hoặc cron job "},{"uri":"https://tunneeeee.github.io/Internship/vi/1-intro-to-container-security/2-threat-modeling/","title":"Mô hình mối đe doạ (Threat Modeling)","tags":[],"description":"","content":"Nội dung chính:\nMô hình STRIDE là gì? Xác định bề mặt tấn công container Vẽ sơ đồ mô hình đe doạ Thực hành mô hình hoá mối đe doạ với container app Mô hình STRIDE là gì? STRIDE là một mô hình giúp xác định các loại mối đe doạ trong hệ thống. Nó gồm:\nThành phần Mối đe doạ S Spoofing – Giả mạo danh tính T Tampering – Can thiệp dữ liệu R Repudiation – Chối bỏ hành vi I Information Disclosure – Rò rỉ TT D Denial of Service – Từ chối dịch vụ E Elevation of Privilege – Leo thang đặc quyền 🧠 STRIDE giúp phân tích từng thành phần trong hệ thống để xác định lỗ hổng tiềm ẩn.\nXác định bề mặt tấn công container Khi triển khai ứng dụng container, cần xác định các điểm có thể bị khai thác:\nContainer Image: chứa lỗ hổng (CVE), mã độc Registry: không được bảo vệ → dễ bị đẩy/pull trái phép Kubernetes API: bị tấn công qua RBAC sai Pod chạy với root: tăng rủi ro leo thang Thông tin nhạy cảm: hardcoded secret, ENV var Vẽ sơ đồ mô hình đe doạ Bạn có thể dùng các công cụ sau để minh hoạ:\n✏️ Draw.io 🔐 Microsoft Threat Modeling Tool 👉 Sơ đồ nên gồm:\nNgười dùng (developer, attacker) Các thành phần: registry, CI/CD, cluster, pod, secrets, DB Ghi chú lỗ hổng tương ứng với STRIDE 📸 Chụp ảnh sơ đồ threat modeling để minh hoạ cho tài liệu sau.\nThực hành mô hình hoá mối đe doạ với container app Chọn một ứng dụng container hoá bạn sẽ triển khai ở lab sau (VD: nginx + flask + mongo) Phân tích từng bước từ build → deploy → chạy → kết nối mạng Liệt kê mối đe doạ với STRIDE và đặt biện pháp phòng chống Bước Mối đe doạ (STRIDE) Phòng chống Push image Tampering Ký image, dùng registry riêng Chạy pod Elevation Privilege Không chạy với root, drop capabilities Kết nối DB Information Disclosure NetworkPolicy, không expose DB 📘 Kết quả mong đợi:\nHiểu rõ các dạng đe doạ bảo mật container Tự tay mô hình hoá mối đe doạ cho ứng dụng bạn sắp triển khai Có sơ đồ threat modeling sẵn sàng dùng trong workshop "},{"uri":"https://tunneeeee.github.io/Internship/vi/2-setup-aws-eks/2-deploy-demo-workloads/","title":"Triển khai workload mẫu trên EKS","tags":[],"description":"","content":"Nội dung chính Tạo namespace riêng cho demo Triển khai ứng dụng nginx và backend Kiểm tra kết nối và chuẩn bị cho các lab tiếp theo Tạo namespace riêng cho demo Namespace giúp cô lập tài nguyên giữa các ứng dụng khác nhau. Đầu tiên, tạo một namespace tên là demo:\nkubectl create namespace demo 📸 Kết quả hiển thị:\nSau đó kiểm tra lại:\nkubectl get ns 📸 Kết quả:\nTriển khai ứng dụng nginx và backend Ứng dụng mẫu gồm 2 Pod:\nnginx (dùng làm frontend) http-echo (dùng làm backend) Tạo file demo-app.yaml với nội dung sau:\napiVersion: v1 kind: Pod metadata: name: nginx namespace: demo spec: containers: - name: nginx image: nginx ports: - containerPort: 80 --- apiVersion: v1 kind: Pod metadata: name: backend namespace: demo spec: containers: - name: backend image: hashicorp/http-echo args: - \u0026#34;-text=Hello from backend\u0026#34; ports: - containerPort: 5678 ▶️ Áp dụng cấu hình:\nkubectl apply -f demo-app.yaml 📸 Kết quả sau khi apply:\nKiểm tra kết nối và chuẩn bị cho các lab tiếp theo Chạy lệnh sau để kiểm tra trạng thái các Pod:\nkubectl get pods -n demo 📸 Kết quả hiển thị:\n✅ Bạn sẽ thấy cả 2 Pod nginx và backend đang ở trạng thái Running.\nỨng dụng mẫu này sẽ được sử dụng xuyên suốt trong các phần tiếp theo như: NetworkPolicy, Falco, OPA\u0026hellip;\nTuỳ chọn: Expose nginx ra ngoài Để truy cập nginx từ bên ngoài (ví dụ từ trình duyệt hoặc curl), bạn có thể expose Pod qua LoadBalancer:\nkubectl expose pod nginx --port=80 --type=LoadBalancer -n demo Ghi chú:\nCâu lệnh này sẽ tạo một Service có địa chỉ IP public (nếu chạy trên cloud như EKS) Bạn có thể dùng lệnh kubectl get svc -n demo để lấy địa chỉ truy cập. 🎉 Bạn đã hoàn tất phần triển khai workload mẫu – sẵn sàng cho các lab bảo mật tiếp theo!\n"},{"uri":"https://tunneeeee.github.io/Internship/vi/2-setup-aws-eks/","title":"Khởi tạo Cluster EKS trên AWS","tags":[],"description":"","content":"Tổng quan Trong chương này, bạn sẽ học cách tạo môi trường Kubernetes thực tế trên AWS bằng Amazon EKS. Đây là bước bắt buộc để triển khai các biện pháp bảo mật container trong các phần sau.\n🎯 Mục tiêu của chương này Trong chương này, bạn sẽ học cách tạo môi trường Kubernetes thực tế trên AWS bằng Amazon EKS. Đây là bước bắt buộc để triển khai các biện pháp bảo mật container trong các phần sau.\n📚 Nội dung chính 2.1 Tạo EKS Cluster\nHướng dẫn từng bước tạo một cluster EKS bằng eksctl, bao gồm IAM role, VPC, node group.\n2.2 Triển khai workload mẫu\nDeploy một ứng dụng mẫu (nginx + backend) lên EKS để làm môi trường test cho các lab tiếp theo.\n✅ Kết quả sau chương này Tạo được 1 cluster Kubernetes thực tế chạy trên AWS Cấu hình đầy đủ quyền IAM và kết nối với kubectl Deploy thành công ứng dụng mẫu để dùng cho các lab bảo mật sau 🚀 Hãy bắt đầu với phần 2.1 – Tạo EKS Cluster nhé!\n"},{"uri":"https://tunneeeee.github.io/Internship/vi/5-security-monitoring-and-response/3-penetration-testing/","title":" Kiểm tra thâm nhập","tags":[],"description":"","content":"Nội dung chính Giới thiệu về Penetration Testing Chuẩn bị môi trường kiểm tra Kiểm tra bảo mật Pod và Container Kiểm tra cấu hình RBAC Kiểm tra Network Policy Sử dụng Kube-Hunter Báo cáo và khắc phục Giới thiệu Penetration Testing (kiểm tra thâm nhập) là quá trình đánh giá bảo mật hệ thống bằng cách mô phỏng các cuộc tấn công thực tế. Đối với Kubernetes, chúng ta cần kiểm tra:\nCấu hình bảo mật của cluster Quyền truy cập và phân quyền Lỗ hổng trong container image Cấu hình network và policy Compliance với các chuẩn bảo mật Chuẩn bị môi trường kiểm tra Bước 1: Tạo namespace riêng cho testing kubectl create namespace pentest kubectl config set-context --current --namespace=pentest Bước 2: Tạo vulnerable pod để test apiVersion: v1 kind: Pod metadata: name: vulnerable-pod namespace: pentest spec: securityContext: runAsUser: 0 runAsGroup: 0 containers: - name: test-container image: nginx:latest securityContext: privileged: true allowPrivilegeEscalation: true capabilities: add: - SYS_ADMIN - NET_ADMIN volumeMounts: - name: host-root mountPath: /host volumes: - name: host-root hostPath: path: / kubectl apply -f vulnerable-pod.yaml Kiểm tra bảo mật Pod và Container Bước 1: Kiểm tra privilege escalation # Truy cập vào pod kubectl exec -it vulnerable-pod -- /bin/bash # Kiểm tra quyền root whoami id # Kiểm tra khả năng truy cập host filesystem ls /host cat /host/etc/passwd Bước 2: Kiểm tra container breakout # Trong pod, kiểm tra mount points mount | grep -E \u0026#34;(proc|sys|dev)\u0026#34; # Kiểm tra capabilities capsh --print # Thử escape container chroot /host /bin/bash Bước 3: Tạo pod với security context tốt hơn apiVersion: v1 kind: Pod metadata: name: secure-pod namespace: pentest spec: securityContext: runAsNonRoot: true runAsUser: 1000 fsGroup: 2000 containers: - name: secure-container image: nginx:1.21-alpine securityContext: allowPrivilegeEscalation: false readOnlyRootFilesystem: true capabilities: drop: - ALL resources: limits: memory: \u0026#34;128Mi\u0026#34; cpu: \u0026#34;100m\u0026#34; requests: memory: \u0026#34;64Mi\u0026#34; cpu: \u0026#34;50m\u0026#34; kubectl apply -f secure-pod.yaml Kiểm tra cấu hình RBAC Bước 1: Tạo ServiceAccount với quyền cao apiVersion: v1 kind: ServiceAccount metadata: name: test-sa namespace: pentest --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: test-binding roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-admin subjects: - kind: ServiceAccount name: test-sa namespace: pentest kubectl apply -f test-rbac.yaml Bước 2: Kiểm tra quyền truy cập # Tạo pod với ServiceAccount kubectl run test-rbac --image=bitnami/kubectl:latest \\ --serviceaccount=test-sa \\ --namespace=pentest \\ --rm -it --restart=Never \\ -- /bin/bash # Trong pod, kiểm tra quyền kubectl auth can-i --list kubectl get secrets --all-namespaces kubectl get nodes Bước 3: Kiểm tra token ServiceAccount # Lấy token kubectl get secret $(kubectl get serviceaccount test-sa -o jsonpath=\u0026#39;{.secrets[0].name}\u0026#39;) -o jsonpath=\u0026#39;{.data.token}\u0026#39; | base64 -d # Sử dụng token để truy cập API curl -k -H \u0026#34;Authorization: Bearer \u0026lt;TOKEN\u0026gt;\u0026#34; https://\u0026lt;API_SERVER\u0026gt;/api/v1/namespaces Kiểm tra Network Policy Bước 1: Tạo pod test network apiVersion: v1 kind: Pod metadata: name: network-test-1 namespace: pentest labels: app: test-app spec: containers: - name: test image: busybox command: [\u0026#34;sleep\u0026#34;, \u0026#34;3600\u0026#34;] --- apiVersion: v1 kind: Pod metadata: name: network-test-2 namespace: pentest labels: app: other-app spec: containers: - name: test image: busybox command: [\u0026#34;sleep\u0026#34;, \u0026#34;3600\u0026#34;] kubectl apply -f network-test-pods.yaml Bước 2: Kiểm tra kết nối trước khi có policy # Lấy IP của pod kubectl get pods -o wide # Test kết nối kubectl exec network-test-1 -- ping -c 3 \u0026lt;IP_OF_POD_2\u0026gt; kubectl exec network-test-1 -- wget -qO- http://\u0026lt;IP_OF_POD_2\u0026gt;:80 Bước 3: Áp dụng Network Policy apiVersion: networking.k8s.io/v1 kind: NetworkPolicy metadata: name: deny-all namespace: pentest spec: podSelector: {} policyTypes: - Ingress - Egress kubectl apply -f network-policy.yaml Bước 4: Kiểm tra lại kết nối # Test kết nối sau khi có policy kubectl exec network-test-1 -- ping -c 3 \u0026lt;IP_OF_POD_2\u0026gt; # Kết quả: Timeout (bị chặn) Sử dụng Kube-Hunter Bước 1: Cài đặt Kube-Hunter # Chạy Kube-Hunter trong container kubectl run kube-hunter --image=aquasec/kube-hunter:latest \\ --namespace=pentest \\ --rm -it --restart=Never \\ -- --remote \u0026lt;CLUSTER_IP\u0026gt; Bước 2: Chạy Kube-Hunter từ bên ngoài # Trên máy local pip install kube-hunter # Scan cluster kube-hunter --remote \u0026lt;CLUSTER_ENDPOINT\u0026gt; Bước 3: Phân tích kết quả Kube-Hunter sẽ báo cáo:\nExposed services Insecure configurations Potential attack vectors Privilege escalation opportunities Báo cáo và khắc phục Tổng hợp lỗ hổng phát hiện High Risk:\nPrivileged containers Host filesystem access Cluster-admin permissions Medium Risk:\nLatest image tags Missing resource limits Weak network policies Low Risk:\nMissing security contexts Outdated images Khuyến nghị khắc phục # Pod Security Standards apiVersion: v1 kind: Namespace metadata: name: secure-namespace labels: pod-security.kubernetes.io/enforce: restricted pod-security.kubernetes.io/audit: restricted pod-security.kubernetes.io/warn: restricted kubectl apply -f secure-namespace.yaml Cleanup # Xóa các tài nguyên test kubectl delete namespace pentest kubectl delete clusterrolebinding test-binding Tổng kết Workshop 🎉 Chúc mừng! Bạn đã hoàn thành workshop \u0026ldquo;Container Security trên AWS EKS\u0026rdquo;\nNhững gì đã học:\nThiết lập EKS cluster an toàn Scanning image với Trivy Hardening với CIS Benchmark Quản lý policy với OPA Gatekeeper Monitoring với Falco Logging với CloudWatch Penetration testing Bước tiếp theo:\nÁp dụng vào môi trường production Thiết lập CI/CD pipeline với security scanning Monitoring và alerting tự động Compliance với các chuẩn bảo mật ✅ Ghi chú quan trọng:\nPenetration testing chỉ nên thực hiện trên môi trường test Luôn có backup trước khi test Tuân thủ các quy định pháp lý về security testing Báo cáo và khắc phục ngay các lỗ hổng phát hiện Cảm ơn bạn đã tham gia workshop! 🚀\n"},{"uri":"https://tunneeeee.github.io/Internship/vi/","title":"Củng cố bảo mật Container và bảo vệ khi chạy (Runtime Protection)","tags":[],"description":"","content":"🔐 Giới thiệu Trong phần này, bạn sẽ tìm hiểu cách củng cố (hardening) môi trường container nhằm giảm thiểu rủi ro bảo mật, đồng thời áp dụng các kỹ thuật giám sát và bảo vệ ở thời điểm runtime để phát hiện và phản ứng kịp thời với các hành vi bất thường.\nKhi ứng dụng đã chạy, container vẫn có thể là mục tiêu tấn công nếu không có lớp bảo vệ phù hợp. Do đó, việc kết hợp cả biện pháp chủ động (hardening) và biện pháp phản ứng (runtime detection) là cực kỳ quan trọng.\n🧩 Nội dung bạn sẽ học Những cấu hình nên áp dụng để harden container và Kubernetes Pod (user, capabilities, readonlyRootFilesystem, seccomp, apparmor…) Sử dụng công cụ như Trivy để kiểm tra lỗ hổng trước khi triển khai Cài đặt và cấu hình Falco để phát hiện các hành vi bất thường trong container Mô phỏng và phân tích các cuộc tấn công thời gian thực Áp dụng các policy runtime để giảm thiểu rủi ro khi container bị khai thác 🎯 Kết quả mong đợi Sau khi hoàn thành phần này, bạn sẽ:\nBiết cách thiết lập cấu hình bảo mật chuẩn cho container/POD Hiểu vai trò của các công cụ giám sát và phát hiện như Falco Có khả năng triển khai hệ thống bảo vệ runtime trong môi trường thực tế Nhận diện sớm các hành vi đáng ngờ và đưa ra phản ứng phù hợp 🚀 Hãy sẵn sàng củng cố môi trường container của bạn trước các mối đe doạ thực tế!\n"},{"uri":"https://tunneeeee.github.io/Internship/vi/4-policy-enforcement-and-runtime-protection/3-automated-remediation/","title":"Tự động phản ứng với vi phạm bằng Falcosidekick","tags":[],"description":"","content":"Nội dung chính Giới thiệu Falcosidekick Triển khai Falcosidekick cùng Falco Cấu hình gửi cảnh báo Kiểm thử cảnh báo Giới thiệu Falcosidekick Falcosidekick là một dịch vụ hỗ trợ Falco gửi cảnh báo đến các hệ thống bên ngoài như:\nSlack, Discord Email Webhook, Kafka, NATS Prometheus, Grafana, Elasticsearch\u0026hellip; Falcosidekick nhận log từ Falco và chuyển tiếp theo cấu hình.\nTriển khai Falcosidekick cùng Falco Bước 1: Cài Falco kèm Falcosidekick helm install falcosidekick falcosecurity/falcosidekick --namespace falco --set config.slack.webhookurl=\u0026#34;https://hooks.slack.com/services/xxx\u0026#34; 🔁 Có thể thay Slack bằng webhook URL khác tùy nhu cầu.\nBước 2: Kiểm tra pod đã chạy kubectl get pods -n falco ✅ Kết quả mong đợi: Có 2 pod đang chạy: falco và falcosidekick\nCấu hình gửi cảnh báo Bạn có thể chỉnh sửa thêm trong file values.yaml nếu muốn cấu hình nhiều hệ thống cảnh báo.\nVí dụ: Gửi về Discord, Prometheus, Webhook\u0026hellip;\nfalcosidekick: config: discord: webhookurl: \u0026#34;https://discord.com/api/webhooks/xxx\u0026#34; webhook: address: \u0026#34;http://your-api-endpoint\u0026#34; Sau đó nâng cấp chart:\nhelm upgrade falco falcosecurity/falco -n falco -f values.yaml Kiểm thử cảnh báo Gây sự kiện bất thường kubectl run -i --tty attacker --image=alpine -- sh Sau đó chạy:\ntouch /etc/passwd Kiểm tra alert gửi đi Kiểm tra log Falcosidekick: kubectl logs -l app=falcosidekick -n falco Xem thông báo trên Slack/Discord/Webhook tùy theo cấu hình. 📸 Chụp ảnh minh họa alert nhận được ở Slack hoặc Discord để đưa vào tài liệu.\nGhi chú Falcosidekick giúp tích hợp Falco với nhiều hệ thống alerting khác nhau. Có thể mở rộng gửi alert đến SIEM, hệ thống automation (XDR, SOAR). "},{"uri":"https://tunneeeee.github.io/Internship/vi/3-container-security-hardening/3-network-policy/","title":"Áp dụng NetworkPolicy trong Kubernetes","tags":[],"description":"","content":" Nội dung chính Giới thiệu về NetworkPolicy Tạo namespace và Pod mẫu Tạo và áp dụng NetworkPolicy Kiểm tra kết quả áp dụng Giới thiệu về NetworkPolicy NetworkPolicy là tính năng của Kubernetes giúp bạn kiểm soát lưu lượng mạng vào/ra giữa các Pod.\nMặc định, mọi Pod trong một cluster có thể giao tiếp với nhau. Khi áp dụng NetworkPolicy, bạn có thể chặn mọi traffic và chỉ cho phép một số kết nối cụ thể.\nTạo namespace và Pod mẫu Bước 1: Tạo namespace riêng kubectl create ns secure-ns Bước 2: Tạo Pod mẫu (nginx) kubectl run nginx --image=nginx -n secure-ns --expose --port=80 📌 Ghi chú: --expose sẽ tự tạo service để bạn dễ test truy cập.\nTạo và áp dụng NetworkPolicy Bước 3: Tạo file deny-all.yaml apiVersion: networking.k8s.io/v1 kind: NetworkPolicy metadata: name: deny-all namespace: secure-ns spec: podSelector: {} policyTypes: - Ingress Lệnh áp dụng:\nkubectl apply -f deny-all.yaml Bước 4: Tạo một Pod test bên ngoài kubectl run busybox --image=busybox:1.28 --rm -it --restart=Never -- sh Thử wget vào nginx service:\nwget -qO- nginx.secure-ns.svc.cluster.local ❌ Kết quả sẽ không truy cập được — đã bị chặn bởi NetworkPolicy.\nKiểm tra kết quả áp dụng Bạn có thể thử thêm các NetworkPolicy cho phép một số IP hoặc namespace cụ thể, ví dụ:\napiVersion: networking.k8s.io/v1 kind: NetworkPolicy metadata: name: allow-same-ns namespace: secure-ns spec: podSelector: matchLabels: run: nginx ingress: - from: - podSelector: {} Sau đó thử truy cập lại từ Pod trong cùng namespace.\n✅ Nếu thành công → bạn đã kiểm soát được traffic đúng như mong muốn.\nGhi chú bổ sung Đảm bảo cluster đã bật CNI plugin hỗ trợ NetworkPolicy (Amazon EKS hỗ trợ sẵn) Sử dụng thêm công cụ như Calico nếu cần advanced policy Áp dụng NetworkPolicy là bước quan trọng trong mô hình Zero Trust cho Kubernetes "},{"uri":"https://tunneeeee.github.io/Internship/vi/3-container-security-hardening/","title":"Tăng cường an ninh Container","tags":[],"description":"","content":" Tổng quan Phần này tập trung vào các biện pháp tăng cường bảo mật container ở tầng cơ bản nhất gồm:\nQuét lỗ hổng container image (Trivy) Kiểm tra tuân thủ chuẩn bảo mật (CIS Benchmark với kube-bench) Áp dụng chính sách mạng để giới hạn traffic giữa các Pod (Kubernetes NetworkPolicy) "},{"uri":"https://tunneeeee.github.io/Internship/vi/4-policy-enforcement-and-runtime-protection/","title":"Policy Enforcement &amp; Runtime Protection","tags":[],"description":"","content":"Overview | Tổng quan This section focuses on advanced container security techniques, specifically:\nPhần này tập trung vào các kỹ thuật bảo mật container nâng cao, cụ thể:\nEnforcing runtime behavior using Falco to detect suspicious activity\nÁp dụng giám sát hành vi thời gian thực bằng Falco để phát hiện các hoạt động bất thường\nImplementing Policy-as-Code with Open Policy Agent (OPA) to control deployment and access\nTriển khai chính sách dưới dạng mã (Policy-as-Code) bằng Open Policy Agent (OPA) để kiểm soát việc triển khai và truy cập\nCombining runtime detection and policy enforcement for proactive defense\nKết hợp phát hiện thời gian thực và thực thi chính sách để bảo vệ chủ động\n"},{"uri":"https://tunneeeee.github.io/Internship/vi/5-security-monitoring-and-response/","title":"Giám sát &amp; Phản hồi Bảo mật","tags":[],"description":"","content":"Tổng quan Giám sát bảo mật và phản hồi sự cố là các thành phần thiết yếu để bảo vệ hệ thống container trong môi trường thực tế. Phần này sẽ hướng dẫn bạn cách ghi log, giám sát các chỉ số an toàn và thử nghiệm tấn công để tăng khả năng phát hiện và phản ứng kịp thời với các mối đe dọa.\nBạn sẽ học cách:\nThu thập và phân tích log từ workload sử dụng CloudWatch Logging. Xây dựng Dashboard bảo mật để theo dõi thời gian thực các chỉ số và dấu hiệu tấn công. Tiến hành Penetration Testing (kiểm thử xâm nhập) để đánh giá năng lực phòng thủ của hệ thống. "},{"uri":"https://tunneeeee.github.io/Internship/vi/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://tunneeeee.github.io/Internship/vi/tags/","title":"Tags","tags":[],"description":"","content":""}]